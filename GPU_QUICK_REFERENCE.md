# GPU Allocation System - Quick Reference

## ğŸ”„ Connection Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CLIENT CONNECTS (WebSocket)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  basic_server.py: websocket_endpoint()                              â”‚
â”‚  â€¢ Generate connection_id = uuid.uuid4()                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GPU Manager: allocate_gpu(connection_id)                           â”‚
â”‚  â€¢ Check available GPUs                                             â”‚
â”‚  â€¢ Find least-loaded GPU with capacity                              â”‚
â”‚  â€¢ Return gpu_id (0, 1, 2, or 3)                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TranscriptionEngine(gpu_id=X)                                      â”‚
â”‚  â€¢ self.device = torch.device(f'cuda:{X}')                          â”‚
â”‚  â€¢ Load ASR model on GPU X                                          â”‚
â”‚  â€¢ Load VAD model on GPU X                                          â”‚
â”‚  â€¢ Load Diarization model on GPU X                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AudioProcessor                                                     â”‚
â”‚  â€¢ Create transcription task on GPU X                               â”‚
â”‚  â€¢ Create diarization task on GPU X                                 â”‚
â”‚  â€¢ Stream results back to client                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Client receives:                                                   â”‚
â”‚  {                                                                  â”‚
â”‚    "type": "config",                                                â”‚
â”‚    "gpu_id": 2,                                                     â”‚
â”‚    "connection_id": "abc-123..."                                    â”‚
â”‚  }                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                         Audio Streaming
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CLIENT DISCONNECTS                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GPU Manager: release_gpu(connection_id)                            â”‚
â”‚  â€¢ Decrement active_connections on GPU X                            â”‚
â”‚  â€¢ Update memory stats                                              â”‚
â”‚  â€¢ Log GPU status                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ GPU Assignment Example (16 Connections)

```
Time  â”‚ Connection â”‚ GPU Assignment â”‚ GPU 0 â”‚ GPU 1 â”‚ GPU 2 â”‚ GPU 3 â”‚
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
T1    â”‚ Conn-1     â”‚ â†’ GPU 0       â”‚  1/4  â”‚  0/4  â”‚  0/4  â”‚  0/4  â”‚
T2    â”‚ Conn-2     â”‚ â†’ GPU 1       â”‚  1/4  â”‚  1/4  â”‚  0/4  â”‚  0/4  â”‚
T3    â”‚ Conn-3     â”‚ â†’ GPU 2       â”‚  1/4  â”‚  1/4  â”‚  1/4  â”‚  0/4  â”‚
T4    â”‚ Conn-4     â”‚ â†’ GPU 3       â”‚  1/4  â”‚  1/4  â”‚  1/4  â”‚  1/4  â”‚
T5    â”‚ Conn-5     â”‚ â†’ GPU 0       â”‚  2/4  â”‚  1/4  â”‚  1/4  â”‚  1/4  â”‚ Round-robin
T6    â”‚ Conn-6     â”‚ â†’ GPU 1       â”‚  2/4  â”‚  2/4  â”‚  1/4  â”‚  1/4  â”‚
T7    â”‚ Conn-7     â”‚ â†’ GPU 2       â”‚  2/4  â”‚  2/4  â”‚  2/4  â”‚  1/4  â”‚
T8    â”‚ Conn-8     â”‚ â†’ GPU 3       â”‚  2/4  â”‚  2/4  â”‚  2/4  â”‚  2/4  â”‚
T9    â”‚ Conn-9     â”‚ â†’ GPU 0       â”‚  3/4  â”‚  2/4  â”‚  2/4  â”‚  2/4  â”‚
T10   â”‚ Conn-10    â”‚ â†’ GPU 1       â”‚  3/4  â”‚  3/4  â”‚  2/4  â”‚  2/4  â”‚
T11   â”‚ Conn-11    â”‚ â†’ GPU 2       â”‚  3/4  â”‚  3/4  â”‚  3/4  â”‚  2/4  â”‚
T12   â”‚ Conn-12    â”‚ â†’ GPU 3       â”‚  3/4  â”‚  3/4  â”‚  3/4  â”‚  3/4  â”‚
T13   â”‚ Conn-13    â”‚ â†’ GPU 0       â”‚  4/4  â”‚  3/4  â”‚  3/4  â”‚  3/4  â”‚
T14   â”‚ Conn-14    â”‚ â†’ GPU 1       â”‚  4/4  â”‚  4/4  â”‚  3/4  â”‚  3/4  â”‚
T15   â”‚ Conn-15    â”‚ â†’ GPU 2       â”‚  4/4  â”‚  4/4  â”‚  4/4  â”‚  3/4  â”‚
T16   â”‚ Conn-16    â”‚ â†’ GPU 3       â”‚  4/4  â”‚  4/4  â”‚  4/4  â”‚  4/4  â”‚ âœ… FULL
T17   â”‚ Conn-17    â”‚ âŒ REJECTED   â”‚  4/4  â”‚  4/4  â”‚  4/4  â”‚  4/4  â”‚ No capacity!
```

---

## ğŸ“Š Memory Layout per GPU

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GPU 0 (16 GB Total)                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Connection 1:   [Whisper: 2.5GB] [Diarization: 1.2GB] = 3.7GB  â”‚
â”‚  Connection 2:   [Whisper: 2.5GB] [Diarization: 1.2GB] = 3.7GB  â”‚
â”‚  Connection 3:   [Whisper: 2.5GB] [Diarization: 1.2GB] = 3.7GB  â”‚
â”‚  Connection 4:   [Whisper: 2.5GB] [Diarization: 1.2GB] = 3.7GB  â”‚
â”‚                                                                  â”‚
â”‚  Total Used: 14.8 GB                                             â”‚
â”‚  Free:       1.2 GB (buffer for operations)                      â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Same layout repeated on GPU 1, GPU 2, GPU 3
```

---

## ğŸ”§ Key Files Modified

```
whisperlivekit/
â”‚
â”œâ”€â”€ ğŸ†• gpu_manager.py              â† NEW: GPU allocation & monitoring
â”‚
â”œâ”€â”€ âœï¸ core.py                     â† MODIFIED: Removed singleton, added gpu_id
â”‚   â€¢ TranscriptionEngine now accepts gpu_id parameter
â”‚   â€¢ Creates torch.device(f'cuda:{gpu_id}')
â”‚
â”œâ”€â”€ âœï¸ basic_server.py             â† MODIFIED: Per-connection GPU assignment
â”‚   â€¢ Calls gpu_manager.allocate_gpu() on connect
â”‚   â€¢ Creates TranscriptionEngine(gpu_id=X) per connection
â”‚   â€¢ Calls gpu_manager.release_gpu() on disconnect
â”‚   â€¢ Added /gpu-status endpoint
â”‚
â”œâ”€â”€ simul_whisper/
â”‚   â””â”€â”€ âœï¸ backend.py              â† MODIFIED: GPU device placement
â”‚       â€¢ SimulStreamingASR accepts gpu_id
â”‚       â€¢ Moves models to specific GPU via model.to(device)
â”‚
â””â”€â”€ diarization/
    â””â”€â”€ âœï¸ sortformer_backend.py   â† MODIFIED: GPU device placement
        â€¢ SortformerDiarization accepts gpu_id
        â€¢ Moves diarization model to specific GPU
```

---

## ğŸš€ Quick Start Commands

### **1. Check GPU Availability**
```bash
nvidia-smi
# Should show 4 GPUs (0, 1, 2, 3)
```

### **2. Start Server**
```bash
whisperlivekit-server --host 0.0.0.0 --port 8000 --model small --diarization
```

### **3. Monitor GPU Status**

**Terminal 1: Watch hardware stats**
```bash
watch -n 1 nvidia-smi
```

**Terminal 2: Check allocation**
```bash
# Pretty-print GPU status
curl -s http://localhost:8000/gpu-status | jq

# Example output:
# {
#   "total_gpus": 4,
#   "total_connections": 8,
#   "max_connections_per_gpu": 4,
#   "gpus": [
#     {
#       "gpu_id": 0,
#       "active_connections": 2,
#       "allocated_memory_gb": 7.45,
#       "free_memory_gb": 8.30,
#       "utilization_percent": 47.3
#     },
#     ...
#   ]
# }
```

### **4. Test Connection**
```bash
# Open WebSocket connection
wscat -c ws://localhost:8000/asr

# You'll receive:
# {"type":"config","useAudioWorklet":false,"gpu_id":0,"connection_id":"abc-123..."}
```

---

## ğŸ“ˆ Performance Metrics

### **Capacity**
- **Max connections**: 16 (4 GPUs Ã— 4 connections)
- **Per-GPU memory**: 16 GB
- **Per-connection memory**: ~3-4 GB
- **Buffer memory**: ~1-2 GB per GPU

### **Latency**
- **Model loading**: ~2-5 seconds (first connection per GPU)
- **Transcription**: 50-100ms per chunk (on dedicated GPU)
- **GPU allocation**: <1ms (in-memory operation)

### **Throughput**
- **Single GPU**: 2-3 concurrent streams
- **4 GPUs**: 12-16 concurrent streams
- **Improvement**: 4-5x increase

---

## âš ï¸ Important Notes

### **Connection Rejection**
When all GPUs are full (16 active connections), new connections receive:
```
WebSocket close code: 1008
Reason: "No GPU resources available"
```

### **Memory Management**
- GPU memory is **NOT pre-allocated**
- Models load on-demand when connection starts
- Memory freed automatically on disconnect via `torch.cuda.empty_cache()`

### **Thread Safety**
- GPU Manager uses `threading.Lock()` for allocation/release
- Safe for concurrent connections

### **Logging**
Every connection logs:
```
INFO: Allocated GPU 2 to connection xyz-789 (Load: 3/4, Memory: 11.2/15.75 GB)
INFO: Connection xyz-789: WebSocket opened on GPU 2
INFO: Released GPU 2 from connection xyz-789 (Remaining: 2 connections, Memory: 7.4/15.75 GB)
```

---

## ğŸ“ Testing Checklist

- [ ] Server starts and detects 4 GPUs
- [ ] First connection gets GPU 0
- [ ] Connections distributed round-robin (0â†’1â†’2â†’3â†’0...)
- [ ] `/gpu-status` shows correct allocation
- [ ] `nvidia-smi` shows GPU memory usage
- [ ] Connection disconnect releases GPU
- [ ] 17th connection is rejected when full

---

## ğŸ“ Support

For issues, check:
1. Server logs: `journalctl -u whisperlivekit -f`
2. GPU status: `curl http://localhost:8000/gpu-status`
3. Hardware: `nvidia-smi`
4. Documentation: `GPU_ALLOCATION_GUIDE.md`

Happy transcribing! ğŸ™ï¸âœ¨
